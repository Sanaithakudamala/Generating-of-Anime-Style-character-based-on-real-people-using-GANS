{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q17p1M6lOse-"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J8Vh4zZPd6V",
        "outputId": "11914f6d-d74b-475d-a476-19c742e16834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "print (tensorflow.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kreGW6dWPpPt"
      },
      "source": [
        "Load and Unzip Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-qt1m70PlXB",
        "outputId": "249de832-5117-4f6e-ab6a-a92d5b701c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVJ8uH25P9ot",
        "outputId": "ba8e6ec5-8edb-41cc-861c-45fd46bef982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/gdrive/MyDrive/GAN_datasets/selfie2anime.zip, /content/gdrive/MyDrive/GAN_datasets/selfie2anime.zip.zip or /content/gdrive/MyDrive/GAN_datasets/selfie2anime.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip /content/gdrive/MyDrive/GAN_datasets/selfie2anime.zip -d /"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcbmKXX0QEeL"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "faces = glob.glob('/trainA/*.jpg')\n",
        "animes = glob.glob(\"/trainB/*.jpg\")\n",
        "faces_test = glob.glob('/testA/*.jpg')\n",
        "animes_test = glob.glob(\"/testB/*.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF23tjFNTs_o"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "zv0RmTnkUDhH",
        "outputId": "1c81902e-b8b3-4cdc-f87f-22cf6e0b38c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human Faces\n",
            "/content/download.png\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1300x1300 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Anime Faces\n",
            "/content/download (1).png\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1300x1300 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure the paths are correct and files exist\n",
        "faces = glob.glob('/content/trainA/*.jpg')  # Added /content/\n",
        "animes = glob.glob(\"/content/trainB/*.jpg\") # Added /content/\n",
        "faces_test = glob.glob('/content/testA/*.jpg') # Added /content/\n",
        "animes_test = glob.glob(\"/content/testB/*.jpg\") # Added /content/\n",
        "\n",
        "print(\"Human Faces\")\n",
        "for k in range(2):\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j in range(9):\n",
        "        # Check if faces list is empty before attempting to choose from it\n",
        "        if not faces:\n",
        "            print(\"/content/download.png\")\n",
        "            break  # Exit the inner loop if faces is empty\n",
        "        file = np.random.choice(faces)\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        plt.subplot(990 + 1 + j)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "    if not faces:\n",
        "        break  # Exit the outer loop if faces is empty\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(\"Anime Faces\")\n",
        "for k in range(2):\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j in range(9):\n",
        "        # Check if animes list is empty before attempting to choose from it\n",
        "        if not animes:\n",
        "            print(\"/content/download (1).png\")\n",
        "            break  # Exit the inner loop if animes is empty\n",
        "        file = np.random.choice(animes)\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        plt.subplot(990 + 1 + j)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "    if not animes:\n",
        "        break  # Exit the outer loop if animes is empty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRV366ktU3YM",
        "outputId": "2170657e-e82f-4598-9076-b444d57d9612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.11/dist-packages (0.23.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons --upgrade --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSf7PzK9VAB9"
      },
      "outputs": [],
      "source": [
        "def encoder_layer(input_layer, filters, bn=True):\n",
        "    x = tensorflow.keras.layers.Conv2D(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
        "    x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "    if bn:\n",
        "        #x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
        "        x = tfa.layers.InstanceNormalization()(x)\n",
        "    return x\n",
        "\n",
        "def decoder_layer(input_layer, skip_input, filters):\n",
        "    #x = tensorflow.keras.layers.UpSampling2D(size=2)(input_layer)\n",
        "    x = tensorflow.keras.layers.Conv2DTranspose(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
        "    x = tensorflow.keras.layers.Activation('relu')(x)\n",
        "    #x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
        "    x = tfa.layers.InstanceNormalization()(x)\n",
        "    x = tensorflow.keras.layers.Concatenate()([x, skip_input])\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud2tghaeVy5-",
        "outputId": "d102ff32-1783-4806-8d91-421793f57a95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.13.0 in /usr/local/lib/python3.11/dist-packages (2.13.0)\n",
            "Collecting tensorflow-addons==0.21.0\n",
            "  Using cached tensorflow_addons-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Using cached tensorflow_addons-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "Installing collected packages: tensorflow-addons\n",
            "  Attempting uninstall: tensorflow-addons\n",
            "    Found existing installation: tensorflow-addons 0.23.0\n",
            "    Uninstalling tensorflow-addons-0.23.0:\n",
            "      Successfully uninstalled tensorflow-addons-0.23.0\n",
            "Successfully installed tensorflow-addons-0.21.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.13.0 --upgrade --no-deps\n",
        "!pip install tensorflow-addons==0.21.0 --upgrade --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5tx91NcXaWp",
        "outputId": "274a5c21-baa4-4d2c-8cf5-2b57d49f08f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: tensorflow-addons==0.20.0 in /usr/local/lib/python3.11/dist-packages (0.20.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.12.0 --upgrade --no-deps\n",
        "!pip install tensorflow-addons==0.20.0 --upgrade --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opItUDTYYYnA"
      },
      "outputs": [],
      "source": [
        "def make_generator():\n",
        "    source_image = tensorflow.keras.layers.Input(shape=(128, 128, 3))\n",
        "    target_style = tensorflow.keras.layers.Input(shape=(16, 16, 512))\n",
        "\n",
        "    e1 = encoder_layer(source_image, 64, bn=False)\n",
        "    e2 = encoder_layer(e1, 128)\n",
        "    e3 = encoder_layer(e2, 256)\n",
        "    # e4 = encoder_layer(e3, 256)\n",
        "    e5 = encoder_layer(e3, 512)\n",
        "    e6 = encoder_layer(e5, 512)\n",
        "    e7 = encoder_layer(e6, 512)\n",
        "\n",
        "    bottle_neck = tensorflow.keras.layers.Conv2D(512, (4,4), strides=(2,2), padding='same')(e7)\n",
        "    b = tensorflow.keras.layers.Activation('relu')(bottle_neck)\n",
        "\n",
        "    d1 = decoder_layer(b, e7, 512)\n",
        "    d2 = decoder_layer(d1, e6, 512)\n",
        "    d3 = decoder_layer(d2, e5, 512)\n",
        "    # d4 = decoder_layer(d3, e4, 256)\n",
        "    d5 = decoder_layer(d3, e3, 256)\n",
        "    d5 = tensorflow.keras.layers.Concatenate()([d5, target_style])\n",
        "    d6 = decoder_layer(d5, e2, 128)\n",
        "    d7 = decoder_layer(d6, e1, 64)\n",
        "\n",
        "    decoded = tensorflow.keras.layers.Conv2DTranspose(3, kernel_size=(4,4), strides=(2,2), padding='same')(d7)\n",
        "    translated_image = tensorflow.keras.layers.Activation('tanh')(decoded)\n",
        "    return source_image, target_style, translated_image\n",
        "\n",
        "source_image, target_style, translated_image = make_generator()\n",
        "generator_network = tensorflow.keras.models.Model(inputs=[source_image, target_style], outputs=translated_image)\n",
        "print (generator_network.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwCZ-Lk7YZ9N"
      },
      "outputs": [],
      "source": [
        "def my_conv_layer(input_layer, filters, bn=True):\n",
        "    x = tensorflow.keras.layers.Conv2D(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
        "    x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "    if bn:\n",
        "        #x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
        "        x = tfa.layers.InstanceNormalization()(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sCAGUyPcvpI",
        "outputId": "0909f9b9-5c67-4ecc-faae-170ac557b4f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdNcPzLXdoSQ",
        "outputId": "b3c73d52-12ac-4c09-c578-fb866d5866e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 64, 64, 64)   3136        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 64, 64, 64)   0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 128)  131200      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 32, 32, 128)  0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " instance_normalization (Instan  (None, 32, 32, 128)  256        ['leaky_re_lu_1[0][0]']          \n",
            " ceNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 16, 16, 256)  524544      ['instance_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 16, 16, 256)  0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " instance_normalization_1 (Inst  (None, 16, 16, 256)  512        ['leaky_re_lu_2[0][0]']          \n",
            " anceNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 8, 8, 512)    2097664     ['instance_normalization_1[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 8, 8, 512)    0           ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " instance_normalization_2 (Inst  (None, 8, 8, 512)   1024        ['leaky_re_lu_3[0][0]']          \n",
            " anceNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 4, 4, 512)    4194816     ['instance_normalization_2[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 4, 4, 512)    0           ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " instance_normalization_3 (Inst  (None, 4, 4, 512)   1024        ['leaky_re_lu_4[0][0]']          \n",
            " anceNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 2, 2, 512)    4194816     ['instance_normalization_3[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 2, 2, 512)    0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " instance_normalization_4 (Inst  (None, 2, 2, 512)   1024        ['leaky_re_lu_5[0][0]']          \n",
            " anceNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 512)    4194816     ['instance_normalization_4[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 512)    0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 2, 2, 512)   4194816     ['activation[0][0]']             \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 2, 2, 512)    0           ['conv2d_transpose[0][0]']       \n",
            "                                                                                                  \n",
            " instance_normalization_5 (Inst  (None, 2, 2, 512)   1024        ['activation_1[0][0]']           \n",
            " anceNormalization)                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 2, 2, 1024)   0           ['instance_normalization_5[0][0]'\n",
            "                                                                 , 'instance_normalization_4[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 4, 4, 512)   8389120     ['concatenate[0][0]']            \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 4, 4, 512)    0           ['conv2d_transpose_1[0][0]']     \n",
            "                                                                                                  \n",
            " instance_normalization_6 (Inst  (None, 4, 4, 512)   1024        ['activation_2[0][0]']           \n",
            " anceNormalization)                                                                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 4, 4, 1024)   0           ['instance_normalization_6[0][0]'\n",
            "                                                                 , 'instance_normalization_3[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 8, 8, 512)   8389120     ['concatenate_1[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 8, 8, 512)    0           ['conv2d_transpose_2[0][0]']     \n",
            "                                                                                                  \n",
            " instance_normalization_7 (Inst  (None, 8, 8, 512)   1024        ['activation_3[0][0]']           \n",
            " anceNormalization)                                                                               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 8, 8, 1024)   0           ['instance_normalization_7[0][0]'\n",
            "                                                                 , 'instance_normalization_2[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 16, 16, 256)  4194560    ['concatenate_2[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 16, 16, 256)  0           ['conv2d_transpose_3[0][0]']     \n",
            "                                                                                                  \n",
            " instance_normalization_8 (Inst  (None, 16, 16, 256)  512        ['activation_4[0][0]']           \n",
            " anceNormalization)                                                                               \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 16, 16, 512)  0           ['instance_normalization_8[0][0]'\n",
            "                                                                 , 'instance_normalization_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 16, 16, 512  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 16, 16, 1024  0           ['concatenate_3[0][0]',          \n",
            "                                )                                 'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, 32, 32, 128)  2097280    ['concatenate_4[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 128)  0           ['conv2d_transpose_4[0][0]']     \n",
            "                                                                                                  \n",
            " instance_normalization_9 (Inst  (None, 32, 32, 128)  256        ['activation_5[0][0]']           \n",
            " anceNormalization)                                                                               \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 32, 32, 256)  0           ['instance_normalization_9[0][0]'\n",
            "                                                                 , 'instance_normalization[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2DTran  (None, 64, 64, 64)  262208      ['concatenate_5[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 64, 64, 64)   0           ['conv2d_transpose_5[0][0]']     \n",
            "                                                                                                  \n",
            " instance_normalization_10 (Ins  (None, 64, 64, 64)  128         ['activation_6[0][0]']           \n",
            " tanceNormalization)                                                                              \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 64, 64, 128)  0           ['instance_normalization_10[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2DTran  (None, 128, 128, 3)  6147       ['concatenate_6[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 128, 128, 3)  0           ['conv2d_transpose_6[0][0]']     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 42,882,051\n",
            "Trainable params: 42,882,051\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "def encoder_layer(input_layer, filters, bn=True):\n",
        "    x = tensorflow.keras.layers.Conv2D(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
        "    x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "    if bn:\n",
        "        #x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
        "        x = tfa.layers.InstanceNormalization()(x)\n",
        "    return x\n",
        "\n",
        "def decoder_layer(input_layer, skip_input, filters):\n",
        "    #x = tensorflow.keras.layers.UpSampling2D(size=2)(input_layer)\n",
        "    x = tensorflow.keras.layers.Conv2DTranspose(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
        "    x = tensorflow.keras.layers.Activation('relu')(x)\n",
        "    #x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
        "    x = tfa.layers.InstanceNormalization()(x)\n",
        "    x = tensorflow.keras.layers.Concatenate()([x, skip_input])\n",
        "    return x\n",
        "\n",
        "def make_generator():\n",
        "    source_image = tensorflow.keras.layers.Input(shape=(128, 128, 3))\n",
        "    target_style = tensorflow.keras.layers.Input(shape=(16, 16, 512))\n",
        "\n",
        "    e1 = encoder_layer(source_image, 64, bn=False)\n",
        "    e2 = encoder_layer(e1, 128)\n",
        "    e3 = encoder_layer(e2, 256)\n",
        "    # e4 = encoder_layer(e3, 256)\n",
        "    e5 = encoder_layer(e3, 512)\n",
        "    e6 = encoder_layer(e5, 512)\n",
        "    e7 = encoder_layer(e6, 512)\n",
        "\n",
        "    bottle_neck = tensorflow.keras.layers.Conv2D(512, (4,4), strides=(2,2), padding='same')(e7)\n",
        "    b = tensorflow.keras.layers.Activation('relu')(bottle_neck)\n",
        "\n",
        "    d1 = decoder_layer(b, e7, 512)\n",
        "    d2 = decoder_layer(d1, e6, 512)\n",
        "    d3 = decoder_layer(d2, e5, 512)\n",
        "    # d4 = decoder_layer(d3, e4, 256)\n",
        "    d5 = decoder_layer(d3, e3, 256)\n",
        "    d5 = tensorflow.keras.layers.Concatenate()([d5, target_style])\n",
        "    d6 = decoder_layer(d5, e2, 128)\n",
        "    d7 = decoder_layer(d6, e1, 64)\n",
        "\n",
        "    decoded = tensorflow.keras.layers.Conv2DTranspose(3, kernel_size=(4,4), strides=(2,2), padding='same')(d7)\n",
        "    translated_image = tensorflow.keras.layers.Activation('tanh')(decoded)\n",
        "    return source_image, target_style, translated_image\n",
        "\n",
        "source_image, target_style, translated_image = make_generator()\n",
        "generator_network = tensorflow.keras.models.Model(inputs=[source_image, target_style], outputs=translated_image)\n",
        "print (generator_network.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S528r2e3dunu"
      },
      "outputs": [],
      "source": [
        "def my_conv_layer(input_layer, filters, bn=True):\n",
        "    x = tensorflow.keras.layers.Conv2D(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
        "    x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "    if bn:\n",
        "        #x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
        "        x = tfa.layers.InstanceNormalization()(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb99DfIZdzrB",
        "outputId": "37e3aab0-1393-452e-a1de-4526eda6ce01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 64, 64, 64)        3136      \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 128)       131200    \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " instance_normalization_11 (  (None, 32, 32, 128)      256       \n",
            " InstanceNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 256)       524544    \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " instance_normalization_12 (  (None, 16, 16, 256)      512       \n",
            " InstanceNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 8, 8, 512)         2097664   \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " instance_normalization_13 (  (None, 8, 8, 512)        1024      \n",
            " InstanceNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 1)           8193      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,766,529\n",
            "Trainable params: 2,766,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        " def make_discriminator():\n",
        "    target_image_input = tensorflow.keras.layers.Input(shape=(128, 128, 3))\n",
        "\n",
        "    x = my_conv_layer(target_image_input, 64, bn=False)\n",
        "    x = my_conv_layer(x, 128)\n",
        "    x = my_conv_layer(x, 256)\n",
        "    # x = my_conv_layer(x, 512)\n",
        "    x = my_conv_layer(x, 512)\n",
        "\n",
        "    patch_features = tensorflow.keras.layers.Conv2D(1, kernel_size=(4,4), strides=(1,1), padding='same')(x)\n",
        "    return target_image_input, patch_features\n",
        "\n",
        "\n",
        "target_image_input, patch_features = make_discriminator()\n",
        "discriminator_network = tensorflow.keras.models.Model(inputs=target_image_input, outputs=patch_features)\n",
        "\n",
        "print (discriminator_network.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiaGN-snd4KR"
      },
      "outputs": [],
      "source": [
        "adam_optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "discriminator_network.compile(loss='mse', optimizer=adam_optimizer, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ca1xVevd8ZN",
        "outputId": "2df9ae76-d570-401f-80e3-35a63b73c9e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 1s 0us/step\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " model_2 (Functional)        (None, 16, 16, 512)       10585152  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,585,152\n",
            "Trainable params: 10,585,152\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "image_input = tensorflow.keras.layers.Input(shape=(128, 128, 3))\n",
        "\n",
        "pre_trained_vgg = tensorflow.keras.applications.vgg19.VGG19(weights='imagenet', input_shape=(128, 128, 3), include_top=False)\n",
        "pre_trained_vgg_model = tensorflow.keras.models.Model(inputs=pre_trained_vgg.input, outputs=pre_trained_vgg.get_layer('block4_conv4').output)\n",
        "\n",
        "pre_trained_image_feautures = pre_trained_vgg_model(image_input)\n",
        "\n",
        "custom_vgg = tensorflow.keras.models.Model(inputs=image_input, outputs=pre_trained_image_feautures)\n",
        "print (custom_vgg.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqklzaNJeBdU",
        "outputId": "b899046c-6cd3-4a97-c8e5-f9ac76435392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " input_9 (InputLayer)           [(None, 16, 16, 512  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " model (Functional)             (None, 128, 128, 3)  42882051    ['input_8[0][0]',                \n",
            "                                                                  'input_9[0][0]']                \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, 8, 8, 1)      2766529     ['model[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 45,648,580\n",
            "Trainable params: 42,882,051\n",
            "Non-trainable params: 2,766,529\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "source_image = tensorflow.keras.layers.Input(shape=(128, 128, 3))\n",
        "target_features = tensorflow.keras.layers.Input(shape=(16, 16, 512))\n",
        "\n",
        "# Domain Transfer\n",
        "custom_vgg.trainable=False\n",
        "fake_anime = generator_network([source_image, target_features])\n",
        "\n",
        "discriminator_network.trainable=False\n",
        "\n",
        "# Tell Real vs Fake\n",
        "real_vs_fake = discriminator_network(fake_anime)\n",
        "\n",
        "face2anime_gan = tensorflow.keras.models.Model(inputs =[source_image, target_features], outputs = [real_vs_fake, fake_anime, fake_anime])\n",
        "face2anime_gan.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFmFdNfFeGl0"
      },
      "outputs": [],
      "source": [
        "def custom_content_loss(y_true, y_pred):\n",
        "    custom_vgg.trainable=False\n",
        "    y_true_features = custom_vgg(y_true)\n",
        "    y_pred_features = custom_vgg(y_pred)\n",
        "    content_loss = tensorflow.keras.losses.mean_absolute_error(y_true_features, y_pred_features)\n",
        "    return content_loss\n",
        "\n",
        "def custom_content_loss2(y_true, y_pred):\n",
        "    custom_vgg.trainable=False\n",
        "    y_true_features = y_true\n",
        "    y_pred_features = custom_vgg(y_pred)\n",
        "    content_loss = tensorflow.keras.losses.mean_absolute_error(y_true_features, y_pred_features)\n",
        "    return content_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmMXQM64eLKy"
      },
      "outputs": [],
      "source": [
        "face2anime_gan.compile(loss=['mse', custom_content_loss, custom_content_loss],\\\n",
        "                       optimizer=adam_optimizer, loss_weights=[1, 1, 0.1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ybQm16Ee6Yc"
      },
      "outputs": [],
      "source": [
        "def show_generator_results(generator_network):\n",
        "    images = []\n",
        "    styles = []\n",
        "    for j in range(7):\n",
        "        file = np.random.choice(faces_test)\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        images.append(img)\n",
        "\n",
        "        # The following line was incorrectly indented\n",
        "        file = np.random.choice(animes_test)\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        styles.append(img)\n",
        "\n",
        "    print ('Human Face Images')\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j, img in enumerate(images):\n",
        "        plt.subplot(770 + 1 + j)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()\n",
        "\n",
        "    # print ('Style Images')\n",
        "    # plt.figure(figsize=(13, 13))\n",
        "    # for j, img in enumerate(styles):\n",
        "    #     plt.subplot(770 + 1 + j)\n",
        "    #     plt.imshow(img)\n",
        "    #     plt.axis('off')\n",
        "    #     #plt.title(trainY[i])\n",
        "    # plt.show()\n",
        "\n",
        "    print ('Customized Anime Version')\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j, img in enumerate(images):\n",
        "        img = (img-127.5)/127.5\n",
        "        style = (styles[j]-127.5)/127.5\n",
        "        output = faces_to_animes(np.array([img]), np.array([style]), generator_network)[0]\n",
        "        output = (output+1.0)/2.0\n",
        "        plt.subplot(770 + 1 + j)\n",
        "        plt.imshow(output)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-0UU4rlfK8D",
        "outputId": "704e8621-309b-49a6-a3cd-bcf46bbfe828"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure the paths are correct and files exist\n",
        "faces = glob.glob('/content/trainA/*.jpg')  # Added /content/\n",
        "animes = glob.glob(\"/content/trainB/*.jpg\") # Added /content/\n",
        "faces_test = glob.glob('/content/testA/*.jpg') # Added /content/\n",
        "animes_test = glob.glob(\"/content/testB/*.jpg\") # Added /content/\n",
        "\n",
        "# Now you can calculate the lengths\n",
        "len(faces), len(animes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3acHmaffhUM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def show_generator_results(generator_network):\n",
        "    images = []\n",
        "    styles = []\n",
        "    for j in range(7):\n",
        "        # Check if directory exists and contains files before proceeding\n",
        "        if not faces_test:\n",
        "            print(\"No test images found in /content/testA/. Skipping image generation.\")\n",
        "            return  # Exit the function early\n",
        "\n",
        "        file = np.random.choice(faces_test)\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        images.append(img)\n",
        "\n",
        "        # The following line was incorrectly indented\n",
        "        # Check if directory exists and contains files before proceeding\n",
        "        if not animes_test:\n",
        "            print(\"No style images found in /content/testB/. Skipping image generation.\")\n",
        "            return  # Exit the function early\n",
        "\n",
        "        file = np.random.choice(animes_test)\n",
        "        img = cv2.imread(file)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        styles.append(img)\n",
        "\n",
        "    print('Human Face Images')\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j, img in enumerate(images):\n",
        "        plt.subplot(770 + 1 + j)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()\n",
        "\n",
        "    print('Customized Anime Version')\n",
        "    plt.figure(figsize=(13, 13))\n",
        "    for j, img in enumerate(images):\n",
        "        img = (img - 127.5) / 127.5\n",
        "        style = (styles[j] - 127.5) / 127.5\n",
        "\n",
        "        # Check if faces_to_animes is defined and callable\n",
        "        if not callable(faces_to_animes):\n",
        "            print(\"Error: faces_to_animes is not defined or callable. Please define it.\")\n",
        "            return\n",
        "\n",
        "        output = faces_to_animes(np.array([img]), np.array([style]), generator_network)[0]\n",
        "        output = (output + 1.0) / 2.0\n",
        "        plt.subplot(770 + 1 + j)\n",
        "        plt.imshow(output)\n",
        "        plt.axis('off')\n",
        "        #plt.title(trainY[i])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoWmeewzfokf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
